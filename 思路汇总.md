1.问题的定义  
```
    SubTaskA, zero-shot、one-shot; 单句分类、双句分类问题。[CLS]SentenceA[SEP]SentenceB[SEP]    
    SubTaskB, pre-train、fine-tune; 句子向量的质量评估。sentence_emb=avg(tokens_embed)   
    备注: avg平均的方式使得句子向量容易被高频Tokens语义主导，可能存在"坍缩"现象。
```  

2.方法调研(2021.10)  
    2.1 多语言模型  

    2.2 少样本学习  

    2.3 数据增强  

    2.4 Sentence向量表征  

    2.4 定稿  
        InfoXLM + EMA + Adversarial Training + Contrastive Learning  

3.效果验证  

4.收获&疑惑  

